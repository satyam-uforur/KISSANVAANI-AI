# ğŸŒ¾ KissanVaani AI â€“ Hindi / Hinglish Voice Farming Assistant

KissanVaani AI is an endâ€‘toâ€‘end **voice-based Question Answering system for Indian farmers**, supporting **Hindi + Hinglish**.  
Ask your farming questions by voice, get **Hinglish transcription**, **retrieved answers from Pinecone**, and **bilingual (English + Hindi) audio replies**.

Built with:

- ğŸ§ **OpenAI Whisper (local)** â€“ Speechâ€‘toâ€‘Text  
- ğŸ§  **SentenceTransformers + Pinecone** â€“ Semantic search  
- ğŸ–¥ **FastAPI** â€“ Backend API  
- ğŸŒ **Streamlit** â€“ Modern web UI  
- ğŸ”Š **gTTS + googletrans** â€“ Textâ€‘toâ€‘Speech in English and Hindi  


---

## ğŸš€ Features

- ğŸ™ **Voice Input**
  - Record from mic (browser) or upload audio (`.wav`, `.mp3`, `.webm`, `.opus`).
- ğŸ§  **Speechâ€‘toâ€‘Text with Whisper**
  - Uses Whisper **medium** model.
  - Forces transcription into **Roman script (â€œHinglishâ€)** for easier downstream processing.
- ğŸ” **Semantic Retrieval with Pinecone**
  - Converts text to embeddings (MiniLM).
  - Queries Pinecone index (`kissanai`) for top farming answers.
  - Supports simple **query expansion** (e.g., `seb` â†’ `apple`).
- ğŸ’¬ **Bilingual Answers**
  - Retrieves answer text (English).
  - Automatically translates to **Hindi** using `googletrans`.
- ğŸ”Š **Audio Responses**
  - Generates **English + Hindi TTS** using `gTTS`.
  - Frontend plays the generated MP3 files directly.
- ğŸŒ **Modern UI**
  - Clean Streamlit app with **day / night theme**.
  - UI language: English / Hindi / Hinglish.
  - Hero section with dynamic greeting for farmers (IST timeâ€‘based).

---

## ğŸ§± Tech Stack

- **Backend**
  - FastAPI
  - Whisper (`medium` model)
  - SentenceTransformers (`all-MiniLM-L6-v2`)
  - Pinecone Vector Database
  - googletrans (EN â†’ HI translation)
  - gTTS (Text â†’ MP3)
  - indicâ€‘transliteration (Hindi â†” Hinglish normalization)

- **Frontend**
  - Streamlit
  - `streamlit-mic-recorder` for inâ€‘browser audio recording

- **Infra / Tools**
  - FFmpeg (audio processing)
  - Python 3.9+  
  - (Optional) CUDA GPU for faster Whisper inference

---

## âš™ï¸ Installation Guide
###### must needed
### 1ï¸âƒ£ Install FFmpeg
Required for audio conversion and processing.

#### ğŸªŸ Windows
Download from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)  
Extract and add the `bin` path to **System Environment Variables**.

Verify:
```bash
ffmpeg -version
````

#### ğŸ§ Linux / ğŸ macOS

```bash
sudo apt install ffmpeg
# or
brew install ffmpeg
```

---

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
# Create venv
python -m venv kissanqa

# Activate
# Windows:
kissanqa\Scripts\activate

# macOS/Linux:
source kissanqa/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

Make sure pip is up to date:

```bash
pip install --upgrade pip
```

Then install all requirements:

```bash
pip install -r requirements.txt
```

If you donâ€™t have one, create `requirements.txt`:

```txt
fastapi
uvicorn
git+https://github.com/openai/whisper.git
streamlit                     
streamlit-audiorecorder       
streamlit-javascript          
streamlit_mic_recorder 
soundfile
pydub
indic-transliteration
sentence-transformers
pinecone
gtts
python-dotenv
python-multipart
requests
```

---
#### NOTE GENERATE YOUR OWN VECTOR 
here is notebook = https://colab.research.google.com/drive/14nSt-UaBG3tcCwqdQHwijH0n96WF55-7?usp=sharing
### 4ï¸âƒ£ Setup Pinecone (Vector Database)

1. Create an account â†’ [https://www.pinecone.io/](https://www.pinecone.io/)
2. Create an index (for example `qa-index`)
3. Copy your **API key**

Then create a `.env` file:

```bash
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=qa-index
```

Youâ€™ll load it in Python using `dotenv`.



### 5ï¸âƒ£ Install Whisper (Speech-to-Text)

Install directly from GitHub:

```bash
pip install git+https://github.com/openai/whisper.git
```

Load it in your backend:

```python
import whisper
model = whisper.load_model("base")
```



### 6ï¸âƒ£ Run Backend (FastAPI)

Start your backend service:

```bash
uvicorn main:app --reload
```

The backend runs at â†’ `http://localhost:8000`



### 7ï¸âƒ£ Run Frontend (Streamlit)

Launch your UI:

```bash
streamlit run app.py
```

Open in your browser: â†’ `http://localhost:8501`


## ğŸ§© Project Structure

```
ğŸ“‚ project_root/
 â”£ ğŸ“ whisper_model/
 â”£ ğŸ“ vosk-model-small-hi-0.22/
 â”£ ğŸ“„ main.py              â† FastAPI backend
 â”£ ğŸ“„ app.py               â† Streamlit frontend
 â”£ ğŸ“„ utils.py             â† Whisper + TTS utilities
 â”£ ğŸ“„ .env                 â† Pinecone config
 â”£ ğŸ“„ requirements.txt
 â”£ ğŸ“„ README.md
```


## ğŸ§  Example Workflow

1. ğŸ™ï¸ Record or upload your voice question
2. ğŸ§  Whisper converts Hindi/Hinglish speech â†’ text
3. ğŸ” Pinecone retrieves the most relevant answers
4. ğŸ’¬ Answer is displayed + converted to speech
5. ğŸ”Š Audio response plays automatically



## ğŸª„ Example Commands

```bash
# 1. Activate environment
kissanqa\Scripts\activate

# 2. Run backend
uvicorn main:app --reload

# 3. Run frontend
streamlit run app.py
```


## ğŸ’¡ Notes

* Use 16 kHz mono audio for best results.
* You can switch Pinecone with FAISS or Chroma if you prefer.
* The backend auto-generates responses and Hindi speech (via gTTS).


## ğŸ§¾ Example Output

```bash
ğŸ™ï¸ Recording question...
ğŸ§  "Kisan ke liye AI kya fayda karta hai?"
ğŸ” Searching vector database...
âœ… Answer: "AI helps farmers with weather prediction and crop yield optimization."
ğŸ”Š Playing Hindi voice response...
```



ğŸ‘¨â€ğŸ’» Authors
**Satyam Tiwari**
& **Ayush Kale**

âœ¨ KissanVaani AI is built with a focus on Indian farmers,
bringing LLMs + Retrieval + Voice together for practical, localâ€‘language support.

ğŸš€ Made with â¤ï¸ for Hindi + Hinglish learners and developers.


